{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "with open('./sources/data.json') as f:\n",
    "    data = json.load(f)\n",
    "result = []\n",
    "for date, value in data:\n",
    "    date = datetime.utcfromtimestamp(int(str(date).rstrip('0'))).date()\n",
    "    value = int(value)\n",
    "    print(date, value)\n",
    "    result.append({'date': str(date), 'value': value})\n",
    "\n",
    "# ## Write the result to a new JSON file\n",
    "with open('./sources/data_edited_date_utc.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "with open('./sources/data.json') as f:\n",
    "    data = json.load(f)\n",
    "result = []\n",
    "for date, value in data:\n",
    "    # date = int(str(date).rstrip('0'))\n",
    "    value = int(value)\n",
    "    # print(date, value)\n",
    "    result.append({'date': str(date), 'value': value, 'value2': int(value * 0.2)})\n",
    "\n",
    "# ## Write the result to a new JSON file\n",
    "with open('./sources/data_edited_value2.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "def concat_parquet_to_duckdb(folder_path, output_file='sec.duckdb'):\n",
    "    files = list(Path(folder_path).glob('*.parquet'))\n",
    "    if Path(output_file).suffix != '.duckdb':\n",
    "        output_file += '.duckdb'\n",
    "\n",
    "    con = duckdb.connect(database=output_file)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # create and populate 'all_data' table\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS main AS SELECT \n",
    "                    accession_number,\n",
    "                    cik,\n",
    "                    cik_name,\n",
    "                    cik_ticker,\n",
    "                    cik_ticker_name,\n",
    "                    cusip,\n",
    "                    name_of_issuer,\n",
    "                    cusip_ticker,\n",
    "                    cusip_ticker_name,\n",
    "                    quarter, \n",
    "                    rdate,    \n",
    "                    shares,\n",
    "                    value,\n",
    "                    tr_id,\n",
    "                    tr_type,\n",
    "                    tr_value,\n",
    "                    tr_shares,\n",
    "                    put_call\n",
    "    FROM parquet_scan('{}')\"\"\".format(files[0]))\n",
    "\n",
    "    # cur.execute(\"CREATE INDEX IF NOT EXISTS idx_accession_number ON main (cik, quarter, cusip, accession_number)\")\n",
    "    \n",
    "    for file in files[1:]:\n",
    "        cur.execute(\"\"\"INSERT INTO main SELECT \n",
    "        accession_number,\n",
    "        cik,\n",
    "        cik_name,\n",
    "        cik_ticker,\n",
    "        cik_ticker_name,\n",
    "        cusip,\n",
    "        name_of_issuer,\n",
    "        cusip_ticker,\n",
    "        cusip_ticker_name,\n",
    "        quarter, \n",
    "        rdate,    \n",
    "        shares,\n",
    "        value,\n",
    "        tr_id,\n",
    "        tr_type,\n",
    "        tr_value,\n",
    "        tr_shares,\n",
    "        put_call\n",
    "    FROM parquet_scan('{}')\"\"\".format(file))\n",
    "\n",
    "    # create and populate 'all_cik_quarter_cusip' table\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS all_cik_quarter_cusip AS \n",
    "        SELECT     \n",
    "            cik,\n",
    "            quarter,\n",
    "            cusip,\n",
    "            ANY_VALUE(cusip_ticker_name) AS cusip_ticker_name,\n",
    "            ANY_VALUE(cik_name) as cik_name,\n",
    "            SUM(value) AS value_usd,\n",
    "            SUM(shares) AS shares,\n",
    "            ROUND(SUM(value) / SUM(shares), 2) as avg_price_usd,\n",
    "            ANY_VALUE(cusip_ticker) as cusip_ticker,\n",
    "            ANY_VALUE(name_of_issuer) as name_of_issuer,\n",
    "            ROUND(SUM(value) / SUM(SUM(value)) OVER (PARTITION BY cik, quarter), 2) AS pct_pct\n",
    "    FROM main.main\n",
    "    WHERE accession_number != 'SYNTHETIC-CLOSE' AND quarter > '1998Q1'  \n",
    "    GROUP BY cik, quarter, cusip\n",
    "    ORDER BY 1, 2, 6 DESC\n",
    "    \"\"\")\n",
    "\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    \n",
    "# call the function\n",
    "# concat_parquet_to_duckdb('/Users/yo_macbook/Documents/app_data/test_cik_consolidated_to')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 3s, sys: 4min, total: 15min 3s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parquet_folder = Path(r'/Users/yo_macbook/Documents/app_data/test_parq')\n",
    "\n",
    "parquet_folder = Path(r'/Users/yo_macbook/Documents/app_data/TR_04_CONS_CIK_CUSIP')\n",
    "output_file = r'/Users/yo_macbook/Documents/app_data/TR_05_TEST_FINAL_DB_PARQ_ARROW/sec.duckdb'\n",
    "\n",
    "concat_parquet_to_duckdb(parquet_folder, output_file='sec_full_tr.duckdb')\n",
    "\n",
    "#  12 sec, - 759 Mb from 83 parquet files of 110 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accession_number', 'cik', 'cik_name', 'cik_ticker', 'cik_ticker_name', 'cusip', 'name_of_issuer', 'cusip_ticker', 'cusip_ticker_name', 'quarter', 'rdate', 'shares', 'value']\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars\n",
    "con = duckdb.connect(database=r'/Users/yo_macbook/Documents/app_data/TR_05_TEST_FINAL_DB_PARQ_ARROW/sec.duckdb')\n",
    "cur = con.cursor()\n",
    "# print(cur.execute(\"\"\"SELECT * FROM information_schema.columns WHERE table_name = 'all_cik_quarter_cusip'\"\"\").pl().head(4))\n",
    "print(cur.execute(\"\"\"SELECT * FROM main limit 3\"\"\").pl().columns)\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\n",
      "  Obtaining dependency information for polars from https://files.pythonhosted.org/packages/ba/55/79665e08ceaf8904ecd4864eec3fae67c34a06b7fa88d931b78528e610a4/polars-0.18.11-cp38-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading polars-0.18.11-cp38-abi3-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Downloading polars-0.18.11-cp38-abi3-macosx_11_0_arm64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars\n",
      "Successfully installed polars-0.18.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accession_number,\n",
    "# cik,\n",
    "# cik_name,\n",
    "# cik_ticker,\n",
    "# cik_ticker_name,\n",
    "# cusip, \n",
    "# cusip_ticker,\n",
    "# cusip_ticker_name,\n",
    "# quarter, \n",
    "# rdate,    \n",
    "# shares,\n",
    "# value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "def concat_parquet_to_duckdb2(folder_path, output_file='sec_full.duckdb'):\n",
    "    files = list(Path(folder_path).glob('*.parquet'))\n",
    "    if Path(output_file).suffix != '.duckdb':\n",
    "        output_file += '.duckdb'\n",
    "\n",
    "    con = duckdb.connect(database=output_file)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # create and populate 'all_data' table\n",
    "    cur.execute(\"\"\"CREATE OR REPLACE TABLE main AS SELECT \n",
    "                    accession_number,\n",
    "                    cik,\n",
    "                    cik_name,\n",
    "                    cik_ticker,\n",
    "                    cik_ticker_name,\n",
    "                    cusip,\n",
    "                    name_of_issuer,\n",
    "                    cusip_ticker,\n",
    "                    cusip_ticker_name,\n",
    "                    quarter, \n",
    "                    rdate,\n",
    "                    fdate,\n",
    "                    shares,\n",
    "                    value \n",
    "    FROM parquet_scan('{}')\"\"\".format(files[0]))\n",
    "\n",
    "    # cur.execute(\"CREATE INDEX idx_on_cik_and_quarter ON main(cik, quarter)\")\n",
    "\n",
    "    ## insert data\n",
    "    for file in files[1:]:\n",
    "        cur.execute(\"\"\"INSERT INTO main SELECT \n",
    "        accession_number,\n",
    "        cik,\n",
    "        cik_name,\n",
    "        cik_ticker,\n",
    "        cik_ticker_name,\n",
    "        cusip,\n",
    "        name_of_issuer,\n",
    "        cusip_ticker,\n",
    "        cusip_ticker_name,\n",
    "        quarter, \n",
    "        rdate,  \n",
    "        fdate,\n",
    "        shares,\n",
    "        value \n",
    "    FROM parquet_scan('{}')\"\"\".format(file))\n",
    "\n",
    "\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    \n",
    "# call the function\n",
    "# concat_parquet_to_duckdb('/Users/yo_macbook/Documents/app_data/test_cik_consolidated_to')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 14.4 s, total: 4min\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parquet_folder = Path(r'/Users/yo_macbook/Documents/app_data/TR_04_CONS_CIK_CUSIP')\n",
    "output_file = r'/Users/yo_macbook/Documents/app_data/TR_05_TEST_FINAL_DB_PARQ_ARROW/sec_full.duckdb'\n",
    "\n",
    "concat_parquet_to_duckdb2(parquet_folder, output_file) \n",
    "\n",
    "#  12 sec, - 759 Mb from 83 parquet files of 110 MB\n",
    "# 12 min - with index on cik and quarter - from all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(database=r'/Users/yo_macbook/Documents/app_data/TR_05_TEST_FINAL_DB_PARQ_ARROW/sec_full.duckdb')\n",
    "cur = con.cursor()\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC_FULL with .arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def concat_parquet_to_arrow(folder_path, output_file='sec_full.arrow'):\n",
    "    files = list(Path(folder_path).glob('*.parquet'))\n",
    "    if Path(output_file).suffix != '.arrow':\n",
    "        output_file += '.arrow'\n",
    "\n",
    "    con = duckdb.connect(database=':memory:')  # Use in-memory DB for temporary processing\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # create and populate 'all_data' table\n",
    "    cur.execute(\"\"\"CREATE OR REPLACE TABLE main AS SELECT \n",
    "                    accession_number,\n",
    "                    cik,\n",
    "                    cik_name,\n",
    "                    cik_ticker,\n",
    "                    cik_ticker_name,\n",
    "                    cusip,\n",
    "                    name_of_issuer,\n",
    "                    cusip_ticker,\n",
    "                    cusip_ticker_name,\n",
    "                    quarter, \n",
    "                    rdate,\n",
    "                    fdate,\n",
    "                    shares,\n",
    "                    value \n",
    "    FROM parquet_scan('{}')\"\"\".format(files[0]))\n",
    "\n",
    "    # cur.execute(\"CREATE INDEX idx_on_cik_and_quarter ON main(cik, quarter)\")\n",
    "\n",
    "    ## insert data\n",
    "    for file in files[1:]:\n",
    "        cur.execute(\"\"\"INSERT INTO main SELECT \n",
    "        accession_number,\n",
    "        cik,\n",
    "        cik_name,\n",
    "        cik_ticker,\n",
    "        cik_ticker_name,\n",
    "        cusip,\n",
    "        name_of_issuer,\n",
    "        cusip_ticker,\n",
    "        cusip_ticker_name,\n",
    "        quarter, \n",
    "        rdate,  \n",
    "        fdate,\n",
    "        shares,\n",
    "        value \n",
    "    FROM parquet_scan('{}')\"\"\".format(file))\n",
    "\n",
    "    # Fetch data into a Pandas DataFrame\n",
    "    df = cur.execute(\"SELECT * FROM main\").fetchdf()\n",
    "\n",
    "    # Convert the DataFrame to Arrow format and save it\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    with pa.OSFile(output_file, 'wb') as sink:\n",
    "        with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "            writer.write_table(table)\n",
    "\n",
    "    cur.close()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 3min 13s, total: 5min 49s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "parquet_folder = Path(r'/Users/yo_macbook/Documents/app_data/TR_04_CONS_CIK_CUSIP')\n",
    "output_file = r'/Users/yo_macbook/Documents/app_data/TR_05_TEST_FINAL_DB_PARQ_ARROW/sec_full.arrow'\n",
    "\n",
    "concat_parquet_to_arrow(parquet_folder, output_file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
